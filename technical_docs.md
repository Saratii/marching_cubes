Engine:
    This project aims to create a fully deformable world with with much finer detail than any other voxel engine.
    It improves on the technical ideas presented by the ClayBook engine https://www.gdcvault.com/play/1025316/Advanced-Graphics-Techniques-Tutorial-GPU
    The end goal is to have all volumetric data abide by variable viscous fluid dynamics, providing hyper-realistic terrain. 
    Despite the project having visual elements, it is not a game.
    The vast majority of development has gone into backend optimizations that would apply to general scientific computing applications or high performance apps. 
    By design, this project targets high end hardware and is optimized for my PC.
    Even in its current state, I have been unable to find any professional game or voxel engine that comes anywhere near the performance of this.
    This project has been so performance critical that it required me to make changes to open source libraries like bevy ecs and crossbeam. 

World Representation:
    The world is represented as volumetric density data where each float is quantized.
    The volumetric data is chunked to allow local world modification and smaller mesh regeneration.
    The Marching Cubes algorithm is used to approximate an isosurface and create a mesh for each chunk out of triangles. 
    Within marching cubes, I used trilinear interpolation to create artifically smooth surfaces from discrete volumetric data.
    The world can be deformed by applying classic SDF logical operations to the density sampled data.
    As the player agent moves around the world, new chunks are generated, leading to an effectively infinite sized world like minecraft. 

Chunk Allocation/Deallocation:
    Because the world is infinite in size (all directions) and the volumetric data is already extremely memory intensive, it must be written and read during runtime from SSD storage. 
    World and chunk data is spread across many different lookup hashmaps and trees. This approach minimizes the memory usage while also providing optimal O(...) complexities for each needed operation.
    Most of the data is stored in a multithreaded Octree allowing spatial relationships. 
    I aggressively multithreaded this part of the project.
    Besides the main render thread I have a managing thread that continually traverses the octree, determining which chunks should be loaded and which should not be loaded based on predefined distances.
    I used an async piping system to send the chunk load requests to distributed worker threads with the manager thread working as a load balancer.
    Each worker thread will determine how to source the data (regenerate vs load from ssd), format the data and pipe it to the render thread for rendering or back to the manager thread.
    The worker threads are responsible for running marching cubes, which is the most expensive operation in the project.

    The chunk generation logic relies on several LOD distances. At the lowest LOD distance chunks are loaded in full with all data in memory, and with colliders.
    At the furthest level, only vertex data exists. Colliders are not added and memory references are dropped. 
    Generation logic recognises generation precidence, allowing chunks nearest to the player to generate first.
    This is important because as the player moves around, chunks that previously did not have colliders need to get colliders before distant chunks generate to prevent player from falling through the map. 

World Generation:
    The entire world is created procedurally.
    The surface data is generated by sampling a fast Fractional Brownian Noise function from the FastNoise2 library built in C++. Even though this is the fastest noise library I could find, chunk generation is still bottlenecked by noise sampling.
    To help surface generation, I use a noise upscaling algorithm to sample each surface fewer times at the cost of less resolution.

Rendering Graphics:
    Graphics quality is unfortunately limited as the nature of destructable terrain and dynamic meshing eliminates most lighting approximations.
    Much of high end renderieng algorithms are also locked behind triple A studios and game engines like Unreal and Unity so nearly all graphic elements are done by hand. 

    The textures I use are procedurally generated and have several levels of LOD KTX data. Mipmap data reduces visual artifacts at distance and can lower the rendering load.
    Custom triplaner shader for texture wrapping. Also allows multiple textures to be loaded onto the same mesh via a texture atlas. 

    To save on PCIE bandwidth I rewrote the vertex shader to excluse UV coordinates.

Persistent File Storage:
    All chunk data and some player data is saved to drive. This allows terrain deform operations to be persistant across runs and also quickens the chunk loading time because chunks dont need to be completely regenerated. 
    Currently chunk data is all stored in a few text files in raw byte format. Storing raw bytes is faster for read and write at the cost of human readability.
    I use several map and flag files that provide over 99.9% compression against raw chunk data. 
    To prevent O(n) lookups I store byte offsets in a seperate file and load them into memory.
    In the future I would like to expand the offset system to include paging, as that unlocks several other optimizations.
    One of the large challenges in data storage is maintaining data ACID. Databases do this automatically but when I tested using both sqlite and LMDB, databases were significantly slower than my custom implementation.

Memory Allocator:
    Through painful amounts of testing and profiling I found that the default windows allocator is garbage.
    For allocations between 400 bytes and 1200 bytes I could consistantly produce a 16x allocation time difference between linux and windows.
    I tested this on multiple PCs and with multiple programs and the timing delay was always present.
    Switching the windows default allocator to mi-malloc allocator resolved this and brought the allocation time to the same levels as linux.
    Even though mi-malloc is designed by microsoft, it is not default in windows because its not as well tested and stability is important.
    This project does huge amounts of data allocations so this one optimization alone provided immense benefit. 

Marching Cubes Optimizations:
    I have went through several iterations of marching cubes algorithms and caching teqniques. 
    Marching cubes is the bottle neck and at the center of all of the hot loops. 
    I also went through several rounds of generating assembly for marching cube functions and optimizing the LLVM output.
    I used various profilers, flamegraphs, and hardware level debuggers to find and minimize ASM hotspots. 

Through performance testing I realized threads dont scale well and 4 threads can do the same work at 16.
This is entirely due to lock contention. Although there were zero deadlocks or even semi-dead locks, lock contention can be improved.
    - Change uniform chunk map to be a read only arc and store a transaction lock. This creates lock free reads in the hottest loop on a chunk load. Neutral on chunk generation. 
    - Same transaction log optimization for index mapping
    - When I created a dedicated write thread and made the worker threads use read only file handles it doubled performance.

Mesh LOD
    We cannot afford to render this many triangles when they dont even account for 1 pixel of screen space so we sample meshes at lower resolution at different distances.
    Implemented 4 conservative distances.
    At distance 1000
        +78% FPS
        -99.87% load time
        -95.84% vertices
        -96.24% triangles
    At distance 2000
        +2650% FPS
        -98.45% load time
        -98.63% vertices
        -98.86% triangles


Failed Technologies:
    8 bit symmetric quantization - too much data loss, causes visual artifacts

    Memory mapped database, LMDB. The internet said it was fast, its not. My custom file loading was 6x faster. 

    GPU compute shader for sampling. The compute shader worked and was extremely fast, but unfortunately the GPU buffer upload and download took longer than a CPU noise implementation while the GPU noise algorithm was near instant.
    Later in the project I would like to revist GPU compute if I decide to run marching cubes and write a custom render pipeline. This will allow all of the heavy compute to run in a shader and avoid most of the GPU upload an downloads.

    I attempted to rewrite all of the SIMD AVX512 instructions for noise computation but it turns out 20+ years of C++ library SIMD development trumps an undergraduate's ability. 

    Moving octree insertions and chunk load map deletions to worker threads instead of manager thread after chunk load decreases performance by 100x.
    Has something to do with memory page locality of the mutex locks, don't understand it but fine. 

    Manifold Dual Contouring is nonsense and dark magic. I could not find a single instance of published MDC library code. 
    I reached out to several CAD development companies who use MDC and none of them were willing to share. 
    My implementation works well and the vertex data meets all invariants under every circumstance I could test. Unfortunately it is still far too slow to use in real time rendering. 
    I checked over a dozen open source MDC implementations and all of them had failing invariants and made huge simplifications to the QEF solving. (Yes im salty I wanted MDC for this project)
    
Drucker-Prager Elastoplasticity - https://math.ucdavis.edu/~jteran/papers/KGPSJT16.pdf, https://www.youtube.com/watch?v=Bqme4WWuIVQ, https://math.ucdavis.edu/~jteran/
visco fluid sim - https://github.com/kotsoft/particle_based_viscoelastic_fluid
MPM (snowball, water, rubber) - https://github.com/Elias-Gu/MPM2D

Mipmaps - https://vulkan-tutorial.com/Generating_Mipmaps

//reference, delete later
https://80.lv/articles/simulating-a-car-drifting-through-mud-with-a-custom-mpm-solver?utm_source=chatgpt.com
https://www.youtube.com/watch?v=rSKMYc1CQHE